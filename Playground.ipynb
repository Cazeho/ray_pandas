{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "import pandas as pd\n",
    "import time \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ray.init(num_cpus=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function definitions...\n",
    "\n",
    "@ray.remote\n",
    "def example(x):\n",
    "    time.sleep(np.random.random())\n",
    "    return np.random.randn()\n",
    "\n",
    "@ray.remote\n",
    "class TestCls():\n",
    "    def __init__(self):\n",
    "        self.g = 1\n",
    "        \n",
    "    def to_go(self, x):\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here, we generate data in redis for remote tasks\n",
    "results = ray.get([example.remote(x) for x in range(4)])\n",
    "\n",
    "# Generating data for Actor tasks\n",
    "actor = TestCls.remote()\n",
    "actor_results = ray.get([actor.to_go.remote(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_state = ray.worker.global_state # Used to access redis client, but also has nice interface for certain information \n",
    "gworker = ray.worker.global_worker # Unused for now\n",
    "rc = global_state.redis_client # Redis Client for interacting with redis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key things included in redis from `rc.keys()`:\n",
    " - Event log\n",
    " - worker info\n",
    " - Remote functions\n",
    " - \"Functions to run\"\n",
    " - Drivers\n",
    " - Redis clients\n",
    " - Actor classes\n",
    " - Actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter() # for printing dicts and lists in a manner easy for the eyes\n",
    "\n",
    "\n",
    "for k in sorted(rc.keys()):\n",
    "    try:\n",
    "        pp.pprint(rc.hgetall(k))\n",
    "        rc.hgetall(k) \n",
    "    except Exception:\n",
    "        print(k, \"Failed \")\n",
    "# Certain return values, such as `event_log:*`, can only be accessed via list calls to redis\n",
    "\n",
    "#         try:\n",
    "#             print('#' * 10)\n",
    "#             print(k)\n",
    "#             pp.pprint(rc.lrange(k, 0, -1))\n",
    "#         except Exception:\n",
    "#             print(k, \"Failed \")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_state.client_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = global_state.task_table()\n",
    "tt_list = list(tt.values())\n",
    "\n",
    "for d in tt_list:\n",
    "    d['TaskSpec']['ReturnObjectIDs'] = [oid.hex() for oid in d['TaskSpec']['ReturnObjectIDs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.io.json import json_normalize\n",
    "\n",
    "result = json_normalize(tt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also parse the event logs in order to get fine grained timing for remote tasks. However, as a user, I'd probably only care about time taken in running the task -- this can be much refined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import json \n",
    "event_list = []\n",
    "\n",
    "# Get and decode all task timing/event logs\n",
    "for key in rc.keys(\"event_log*\"):\n",
    "    content = rc.lrange(key, 0, -1)\n",
    "    event_list.append(json.loads(content[0].decode())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# This seems to be the best way to do the event_log -> dataframe pipeline. \n",
    "# First generate a (key, [value]) mapping for all tasks and then apply some pandas operations to convert.\n",
    "\n",
    "# event_dict is used to store timing info\n",
    "event_dict = defaultdict(lambda: np.full(len(event_list), np.nan))\n",
    "\n",
    "# info_dict is used to store meta data - such as function names and task id\n",
    "info_dict = defaultdict(lambda: [None] * len(event_list))\n",
    "\n",
    "for i, task_event in enumerate(event_list):\n",
    "    for event in (task_event):\n",
    "        time, label, startstop, info = event\n",
    "        event_dict[(label, startstop)][i] = time\n",
    "        if info:\n",
    "            for k in info:\n",
    "                info_dict[k][i] = info[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The tuple keys for `event_dict` produce a hierarchical index, which could be useful. However, joining or merging it \n",
    "# with other non-hierarchical indices will throw away this structure.\n",
    "\n",
    "edf = pd.DataFrame(event_dict) \n",
    "edf.rename(columns={1: 'start', 2:'end'}, inplace=True)\n",
    "# edf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = pd.DataFrame(info_dict)\n",
    "idf.columns = pd.MultiIndex.from_tuples([(c, '') for c in idf]) # this is non-idempotent!\n",
    "# idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_table = pd.concat([idf, edf], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we join two tables together as an example\n",
    "remote_table.merge(result, left_on=\"task_id\", right_on=\"TaskSpec.TaskID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "\n",
    "- Error messages logging (specifics - which node, which function call, which actor, what time)\n",
    "- DataFrame for actor-specific usage - (parent actor, which node, etc.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
